{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main_Code.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMsuHkfI6/AZMhX7pKDIfNa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kUNbTghu1Ks-","executionInfo":{"status":"ok","timestamp":1624287424007,"user_tz":-420,"elapsed":15235,"user":{"displayName":"Pham Ngoc Thai","photoUrl":"","userId":"10753663051166648164"}},"outputId":"039fc4b2-847e-4ba4-ba40-6f1b5ea4a93f"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KC1Lv2fkO_9Q","executionInfo":{"status":"ok","timestamp":1624287433885,"user_tz":-420,"elapsed":6046,"user":{"displayName":"Pham Ngoc Thai","photoUrl":"","userId":"10753663051166648164"}}},"source":["#Required Packages\n","import dlib\n","import cv2\n","from imutils import face_utils\n","from scipy.spatial import distance \n","import math\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.base import BaseEstimator, TransformerMixin\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.tree import DecisionTreeClassifier\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","import warnings\n","from sklearn import preprocessing\n","\n","p = \"/content/gdrive/MyDrive/CV_collab_workspace/AI-Project-Final-from-Team-9/Codes/4-Main_Code/shape_predictor_68_face_landmarks.dat\"\n","detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor(p)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"11tDTpMhPTsN","executionInfo":{"status":"ok","timestamp":1624287440963,"user_tz":-420,"elapsed":350,"user":{"displayName":"Pham Ngoc Thai","photoUrl":"","userId":"10753663051166648164"}}},"source":["#Feature Functions\n","\n","def eye_aspect_ratio(eye):\n","\tA = distance.euclidean(eye[1], eye[5])\n","\tB = distance.euclidean(eye[2], eye[4])\n","\tC = distance.euclidean(eye[0], eye[3])\n","\tear = (A + B) / (2.0 * C)\n","\treturn ear\n","\n","def mouth_aspect_ratio(mouth):\n","    A = distance.euclidean(mouth[14], mouth[18])\n","    C = distance.euclidean(mouth[12], mouth[16])\n","    mar = (A ) / (C)\n","    return mar\n","\n","def circularity(eye):\n","    A = distance.euclidean(eye[1], eye[4])\n","    radius  = A/2.0\n","    Area = math.pi * (radius ** 2)\n","    p = 0\n","    p += distance.euclidean(eye[0], eye[1])\n","    p += distance.euclidean(eye[1], eye[2])\n","    p += distance.euclidean(eye[2], eye[3])\n","    p += distance.euclidean(eye[3], eye[4])\n","    p += distance.euclidean(eye[4], eye[5])\n","    p += distance.euclidean(eye[5], eye[0])\n","    return 4 * math.pi * Area /(p**2)\n","\n","def mouth_over_eye(eye):\n","    ear = eye_aspect_ratio(eye)\n","    mar = mouth_aspect_ratio(eye)\n","    mouth_eye = mar/ear\n","    return mouth_eye\n","\n","\n","def average(y_pred):\n","    for i in range(len(y_pred)):\n","        if i % 240 == 0 or (i+1) % 240 == 0:\n","            pass\n","        else: \n","            average = float(y_pred[i-1] +  y_pred[i] + y_pred[i+1])/3\n","            if average >= 0.5:\n","                y_pred[i] = 1\n","            else:\n","                y_pred[i] = 0\n","    return y_pred"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"XPwWi1CAPYLe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624287846422,"user_tz":-420,"elapsed":297,"user":{"displayName":"Pham Ngoc Thai","photoUrl":"","userId":"10753663051166648164"}},"outputId":"479a3101-9961-4df0-df2f-f0ba3bc50b37"},"source":["#Read in the Data file to Train Model\n","import pandas as pd\n","df = pd.read_csv('/content/gdrive/MyDrive/CV_collab_workspace/AI-Project-Final-from-Team-9/Data/final_with_main_features.csv',sep=',')\n","df = df.drop(df.columns[0],axis=1)\n","\n","train_percentage = 14/22\n","train_index = int(len(df)*train_percentage)\n","test_index = len(df)-train_index\n","\n","df_train = df[:train_index]\n","df_test = df[-test_index:]\n","\n","X_test = df_test.drop([\"Y\"],axis=1)\n","y_test = df_test[\"Y\"]\n","\n","X_train = df_train.drop('Y',axis=1)\n","y_train = df_train['Y']\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["(6720, 8)\n","(6720,)\n","(3840, 8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5CM4yTCZPbOo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624287856088,"user_tz":-420,"elapsed":5096,"user":{"displayName":"Pham Ngoc Thai","photoUrl":"","userId":"10753663051166648164"}},"outputId":"056b518a-8d55-486b-8530-b6665485adc2"},"source":["#KNN\n","\n","acc3_list = []\n","f1_score3_list = []\n","roc_3_list = []\n","from sklearn.neighbors import KNeighborsClassifier\n","for i in range(1,30):\n","    neigh = KNeighborsClassifier(n_neighbors=i)\n","    neigh.fit(X_train, y_train) \n","    pred_KN = neigh.predict(X_test)\n","    pred_KN = average(pred_KN)\n","    y_score_3 = neigh.predict_proba(X_test)[:,1]\n","    acc3_list.append(accuracy_score(y_test, pred_KN))\n","    f1_score3_list.append(metrics.f1_score(y_test, pred_KN))\n","    roc_3_list.append(metrics.roc_auc_score(y_test, y_score_3))\n","    \n","    \n","neigh = KNeighborsClassifier(n_neighbors=acc3_list.index(max(acc3_list))+1)\n","neigh.fit(X_train, y_train) \n","pred_KN = neigh.predict(X_test)\n","pred_KN = average(pred_KN)\n","y_score_3 = neigh.predict_proba(X_test)[:,1]\n","acc3 = accuracy_score(y_test, pred_KN)\n","f1_score_3 = metrics.f1_score(y_test, pred_KN)\n","roc_3 = metrics.roc_auc_score(y_test, y_score_3)\n","print([acc3,f1_score_3,roc_3])\n","print(confusion_matrix(y_test, pred_KN))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[0.8127604166666667, 0.7734005672864798, 0.8883490668402777]\n","[[1894   26]\n"," [ 693 1227]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IAg0pphAPeRz","executionInfo":{"status":"ok","timestamp":1624287903934,"user_tz":-420,"elapsed":544,"user":{"displayName":"Pham Ngoc Thai","photoUrl":"","userId":"10753663051166648164"}}},"source":["def model(landmarks):\n","\n","    features = pd.DataFrame(columns=[\"EAR\",\"MAR\",\"Circularity\",\"MOE\"])\n","\n","    eye = landmarks[36:68]\n","    ear = eye_aspect_ratio(eye)\n","    mar = mouth_aspect_ratio(eye)\n","    cir = circularity(eye)\n","    mouth_eye = mouth_over_eye(eye)\n","\n","    df = features.append({\"EAR\":ear,\"MAR\": mar,\"Circularity\": cir,\"MOE\": mouth_eye},ignore_index=True)\n","\n","    df[\"EAR_N\"] = (df[\"EAR\"]-mean[\"EAR\"])/ std[\"EAR\"]\n","    df[\"MAR_N\"] = (df[\"MAR\"]-mean[\"MAR\"])/ std[\"MAR\"]\n","    df[\"Circularity_N\"] = (df[\"Circularity\"]-mean[\"Circularity\"])/ std[\"Circularity\"]\n","    df[\"MOE_N\"] = (df[\"MOE\"]-mean[\"MOE\"])/ std[\"MOE\"]\n","\n","    print(df.shape)  \n","    Result = neigh.predict(df)\n","    if Result == 1:\n","        Result_String = \"Drowsy\"\n","    else:\n","        Result_String = \"Alert\"\n","    \n","\n","    return Result_String, df.values"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"k8S09NBZPhy9"},"source":["def calibration():\n","    data = []\n","    cap = cv2.VideoCapture(\"/content/gdrive/MyDrive/CV_collab_workspace/data/Fold5_part2/57/10.MOV\")\n","    count = 0\n","    while True:\n","        # Getting out image by webcam \n","        _, image = cap.read()\n","        # Converting the image to gray scale\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        # Get faces into webcam's image\n","        rects = detector(image, 0)\n","\n","        # For each detected face, find the landmark.\n","        for (i, rect) in enumerate(rects):\n","            # Make the prediction and transfom it to numpy array\n","            shape = predictor(gray, rect)\n","            shape = face_utils.shape_to_np(shape)\n","            data.append(shape)\n","            cv2.putText(image,\"Calibrating...\", bottomLeftCornerOfText, font, fontScale, fontColor,lineType)\n","\n","            # Draw on our image, all the finded cordinate points (x,y) \n","            for (x, y) in shape:\n","                cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n","\n","        # Show the image\n","        # cv2.imshow(\"Output\", image)\n","        ++countF\n","        if i == 3:\n","            break\n","\n","    cv2.destroyAllWindows()\n","    cap.release()\n","    \n","    \n","    features_test = []\n","    for d in data:\n","        eye = d[36:68]\n","        ear = eye_aspect_ratio(eye)\n","        mar = mouth_aspect_ratio(eye)\n","        cir = circularity(eye)\n","        mouth_eye = mouth_over_eye(eye)\n","        features_test.append([ear, mar, cir, mouth_eye])\n","    \n","    features_test = np.array(features_test)\n","    x = features_test\n","    y = pd.DataFrame(x,columns=[\"EAR\",\"MAR\",\"Circularity\",\"MOE\"])\n","    df_means = y.mean(axis=0)\n","    df_std = y.std(axis=0)\n","    \n","    return df_means,df_std\n","\n","font                   = cv2.FONT_HERSHEY_SIMPLEX\n","bottomLeftCornerOfText = (10,400)\n","fontScale              = 1\n","fontColor              = (255,255,255)\n","lineType               = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1yPnBW1PkuK"},"source":["def live():\n","    cap = cv2.VideoCapture(\"/content/gdrive/MyDrive/CV_collab_workspace/data/Fold5_part2/57/10.MOV\")\n","    data = []\n","    result = []\n","    while True:\n","        # Getting out image by webcam \n","        _, image = cap.read()\n","        # Converting the image to gray scale\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        # Get faces into webcam's image\n","        rects = detector(image, 0)\n","\n","        # For each detected face, find the landmark.\n","        for (i, rect) in enumerate(rects):\n","            # Make the prediction and transfom it to numpy array\n","            shape = predictor(gray, rect)\n","            shape = face_utils.shape_to_np(shape)\n","            Result_String, features = model(shape)\n","            cv2.putText(image,Result_String, bottomLeftCornerOfText, font, fontScale, fontColor,lineType)\n","            data.append (features)\n","            result.append(Result_String)\n","\n","            # Draw on our image, all the finded cordinate points (x,y) \n","            for (x, y) in shape:\n","                cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n","\n","        # Show the image\n","        # cv2.imshow(\"Output\", image)\n","\n","        k = cv2.waitKey(300) & 0xFF\n","        if k == 27:\n","            break\n","\n","    cv2.destroyAllWindows()\n","    cap.release()\n","    \n","    return data,result\n","\n","font                   = cv2.FONT_HERSHEY_SIMPLEX\n","bottomLeftCornerOfText = (10,400)\n","fontScale              = 1\n","fontColor              = (255,255,255)\n","lineType               = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vX4RZxzWPmj7","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"error","timestamp":1624201280429,"user_tz":-420,"elapsed":2174,"user":{"displayName":"Pham Ngoc Thai","photoUrl":"","userId":"10753663051166648164"}},"outputId":"a44dfaa7-c89f-474c-f215-7edec72afab1"},"source":["#Run Calibration\n","mean, std = calibration()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"DisabledFunctionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-d1cdcca454b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Run Calibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-3b41c79363e0>\u001b[0m in \u001b[0;36mcalibration\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Show the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"]}]},{"cell_type":"code","metadata":{"id":"YE9FOpx8PoqQ"},"source":["#Run Demonstration\n","features, result = live()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQU25i5OPrKK"},"source":["#Plot Results\n","features =np.vstack(features)\n","y = pd.DataFrame(features,columns=[\"EAR\",\"MAR\",\"Circularity\",\"MOE\",\"EAR_N\",\"MAR_N\",\"Circularity_N\",\"MOE_N\"])\n","y = y.drop(columns=[\"EAR_N\",\"MAR_N\",\"Circularity_N\",\"MOE_N\"])\n","\n","x = y.values #returns a numpy array\n","min_max_scaler = preprocessing.MinMaxScaler()\n","x_scaled = min_max_scaler.fit_transform(x)\n","y = pd.DataFrame(x_scaled,columns=[\"Eye Aspect Ratio\",\"Mouth Aspect Ratio\",\"Eye Circularity\",\"Mouth over Eye\"])\n","\n","\n","y [\"Result\"] = result\n","\n","\n","fig, (ax1, ax2) = plt.subplots(nrows=2,\n","                                ncols=1,\n","                                sharex=True,\n","                                sharey=False,\n","                                figsize=(15, 8))\n","\n","ax1.set_title(\"Normalised Features\")\n","#ax1.plot(y[\"Eye Aspect Ratio\"])\n","#ax1.plot(y[\"Mouth Aspect Ratio\"])\n","ax1.plot(y[\"Eye Circularity\"])\n","ax1.plot(y[\"Mouth over Eye\"])\n","ax1.legend(loc=\"best\")\n","ax1.set_ylabel('Feature Value')\n","\n","\n","ax2.plot(y[\"Result\"],marker = '.', color = \"Black\")\n","ax2.set_xlabel('Time (Frames Captured)')"],"execution_count":null,"outputs":[]}]}